{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0qGDdiBI2YIE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDVdhkOtJb7t"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F38iHAuKJfzp"
   },
   "source": [
    "### Configure your API keys\n",
    "\n",
    "To fine-tune PaliGemma, you need to provide your HuggingFace Token and Roboflow API key. Follow these steps:\n",
    "\n",
    "- Open your [`HuggingFace Settings`](https://huggingface.co/settings) page. Click `Access Tokens` then `New Token` to generate new token.\n",
    "- Go to your [`Roboflow Settings`](https://app.roboflow.com/settings/api) page. Click `Copy`. This will place your private key in the clipboard.\n",
    "- In Colab, go to the left pane and click on `Secrets` (🔑).\n",
    "    - Store HuggingFace Access Token under the name `HF_TOKEN`.\n",
    "    - Store Roboflow API Key under the name `ROBOFLOW_API_KEY`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLEC5yoEJi4J"
   },
   "source": [
    "### Select the runtime\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `L4 GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpaminvvJm3H",
    "outputId": "7ee0fccf-dc72-4071-f8a1-5422aed165e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 16 02:11:03 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX               On  | 00000000:5E:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8              29W / 280W |      3MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN RTX               On  | 00000000:86:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8               2W / 280W |  10491MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN RTX               On  | 00000000:AF:00.0 Off |                  N/A |\n",
      "|  0%   33C    P8               6W / 280W |      3MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EA4j12iJxfW"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gq-vRquBwwbX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install -q roboflow maestro==0.2.0rc3\n",
    "!pip install -q roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VwpMjR6J-EQ"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0sQCgrUfCtj",
    "outputId": "982c6ca5-8740-4729-82bb-57be40d0e15c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "# from google.colab import userdata\n",
    "\n",
    "# ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
    "ROBOFLOW_API_KEY = \"O4znBVbtIB84A6sTVYh6\"\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "\n",
    "version = rf.workspace(\"roboflow-jvuqo\").project(\"poker-cards-fmjio\").version(4)\n",
    "dataset = version.download(\"florence2-od\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiBFaHHDKX2Q",
    "outputId": "d60084c5-8d61-4c3a-93d1-1a7a8703f5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"image\":\"IMG_20220316_172418_jpg.rf.e3cb4a86dc0247e71e3697aa3e9db923.jpg\",\"prefix\":\"<OD>\",\"suffix\":\"9 of clubs<loc_138><loc_100><loc_470><loc_448>10 of clubs<loc_388><loc_145><loc_670><loc_453>jack  of clubs<loc_566><loc_166><loc_823><loc_432>queen of clubs<loc_365><loc_465><loc_765><loc_999>king of clubs<loc_601><loc_440><loc_949><loc_873>\"}\n",
      "{\"image\":\"IMG_20220316_171515_jpg.rf.e3b1932bb375b3b3912027647586daa8.jpg\",\"prefix\":\"<OD>\",\"suffix\":\"5 of clubs<loc_554><loc_2><loc_763><loc_467>6 of clubs<loc_399><loc_79><loc_555><loc_466>7 of clubs<loc_363><loc_484><loc_552><loc_905>8 of clubs<loc_535><loc_449><loc_757><loc_971>\"}\n",
      "{\"image\":\"IMG_20220316_165139_jpg.rf.e30257ec169a2bfdfecb693211d37250.jpg\",\"prefix\":\"<OD>\",\"suffix\":\"9 of diamonds<loc_596><loc_535><loc_859><loc_982>jack of diamonds<loc_211><loc_546><loc_411><loc_880>queen of diamonds<loc_430><loc_34><loc_692><loc_518>king of diamonds<loc_223><loc_96><loc_451><loc_523>10 of diamonds<loc_387><loc_542><loc_604><loc_925>\"}\n",
      "{\"image\":\"IMG_20220316_143407_jpg.rf.e1eb3be3efc6c3bbede436cfb5489e7c.jpg\",\"prefix\":\"<OD>\",\"suffix\":\"ace of hearts<loc_345><loc_315><loc_582><loc_721>2 of hearts<loc_709><loc_115><loc_888><loc_509>3 of hearts<loc_529><loc_228><loc_735><loc_613>4 of hearts<loc_98><loc_421><loc_415><loc_845>\"}\n",
      "{\"image\":\"IMG_20220316_165139_jpg.rf.e4c229a9128494d17992cbe88af575df.jpg\",\"prefix\":\"<OD>\",\"suffix\":\"9 of diamonds<loc_141><loc_18><loc_404><loc_465>jack of diamonds<loc_589><loc_120><loc_789><loc_454>queen of diamonds<loc_308><loc_482><loc_570><loc_966>king of diamonds<loc_549><loc_477><loc_777><loc_904>10 of diamonds<loc_396><loc_75><loc_613><loc_458>\"}\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 {dataset.location}/train/annotations.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgyVKInOKbxT"
   },
   "source": [
    "## Fine-tune Florence-2 on detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkMwxcXN09jx",
    "outputId": "c899e23c-d468-4b1d-c857-e0cf77ebdfa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mmaestro paligemma train [OPTIONS]\u001b[0m\u001b[1m                                      \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      " Train PaliGemma model                                                          \n",
      "                                                                                \n",
      "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[31m*\u001b[0m  \u001b[1;36m-\u001b[0m\u001b[1;36m-dataset\u001b[0m                                 \u001b[1;33mTEXT   \u001b[0m  Path to the dataset    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       used for training      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: None]       \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2;31m[required]            \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-model_id\u001b[0m                                \u001b[1;33mTEXT   \u001b[0m  Identifier for the     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       PaliGemma model        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default:             \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2mgoogle/paligemma-3b-p…\u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-revision\u001b[0m                                \u001b[1;33mTEXT   \u001b[0m  Revision of the model  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       to use                 \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: float16]    \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-device\u001b[0m                                  \u001b[1;33mTEXT   \u001b[0m  Device to use for      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       training               \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: cuda:0]     \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-cache_dir\u001b[0m                               \u001b[1;33mTEXT   \u001b[0m  Directory to cache the \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       model                  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: None]       \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-epochs\u001b[0m                                  \u001b[1;33mINTEGER\u001b[0m  Number of training     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       epochs                 \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: 10]         \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-optimizer\u001b[0m                               \u001b[1;33mTEXT   \u001b[0m  Optimizer to use for   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       training               \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: adamw]      \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-lr\u001b[0m                                      \u001b[1;33mFLOAT  \u001b[0m  Learning rate for the  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       optimizer              \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: 1e-05]      \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-lr_scheduler\u001b[0m                            \u001b[1;33mTEXT   \u001b[0m  Learning rate          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       scheduler              \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: linear]     \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-batch_size\u001b[0m                              \u001b[1;33mINTEGER\u001b[0m  Batch size for         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       training               \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: 4]          \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-val_batch_size\u001b[0m                          \u001b[1;33mINTEGER\u001b[0m  Batch size for         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       validation             \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: None]       \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-num_workers\u001b[0m                             \u001b[1;33mINTEGER\u001b[0m  Number of workers for  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       data loading           \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: 0]          \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-val_num_workers\u001b[0m                         \u001b[1;33mINTEGER\u001b[0m  Number of workers for  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       validation data        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       loading                \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: None]       \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-lora_r\u001b[0m                                  \u001b[1;33mINTEGER\u001b[0m  Rank of the LoRA       \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       update matrices        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: 8]          \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-lora_alpha\u001b[0m                              \u001b[1;33mINTEGER\u001b[0m  Scaling factor for the \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       LoRA update            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: 8]          \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-lora_dropout\u001b[0m                            \u001b[1;33mFLOAT  \u001b[0m  Dropout probability    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       for LoRA layers        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: 0.05]       \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-bias\u001b[0m                                    \u001b[1;33mTEXT   \u001b[0m  Which bias to train    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: none]    \u001b[0m    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-use_rslora\u001b[0m           \u001b[1;35m-\u001b[0m\u001b[1;35m-no_use_rslora\u001b[0m    \u001b[1;33m       \u001b[0m  Whether to use RSLoRA  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: use_rslora]\u001b[0m  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-init_lora_weights\u001b[0m                       \u001b[1;33mTEXT   \u001b[0m  How to initialize LoRA \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       weights                \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: gaussian]   \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-output_dir\u001b[0m                              \u001b[1;33mTEXT   \u001b[0m  Directory to save      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       output files           \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default:             \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m./training/paligemma] \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-metrics\u001b[0m                                 \u001b[1;33mTEXT   \u001b[0m  List of metrics to     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       track during training  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                                    \u001b[1;33m       \u001b[0m  Show this message and  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       exit.                  \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!maestro paligemma train --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9IlCLXepqTv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1mTraining configuration\u001b[0m\n",
      "\u001b[1m{\u001b[0m\n",
      "    \u001b[32m'dataset'\u001b[0m: \n",
      "\u001b[32m'/mnt/nas2/users/sbchoi/multimodal-maestro/cookbooks/poker-cards-4'\u001b[0m,\n",
      "    \u001b[32m'model_id'\u001b[0m: \u001b[32m'google/paligemma-3b-pt-224'\u001b[0m,\n",
      "    \u001b[32m'revision'\u001b[0m: \u001b[32m'float16'\u001b[0m,\n",
      "    \u001b[32m'device'\u001b[0m: \u001b[1;35mdevice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'cuda'\u001b[0m, \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[32m'cache_dir'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[32m'epochs'\u001b[0m: \u001b[1;36m10\u001b[0m,\n",
      "    \u001b[32m'optimizer'\u001b[0m: \u001b[32m'adamw'\u001b[0m,\n",
      "    \u001b[32m'lr'\u001b[0m: \u001b[1;36m5e-06\u001b[0m,\n",
      "    \u001b[32m'lr_scheduler'\u001b[0m: \u001b[32m'linear'\u001b[0m,\n",
      "    \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
      "    \u001b[32m'val_batch_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
      "    \u001b[32m'val_num_workers'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[32m'lora_r'\u001b[0m: \u001b[1;36m8\u001b[0m,\n",
      "    \u001b[32m'lora_alpha'\u001b[0m: \u001b[1;36m8\u001b[0m,\n",
      "    \u001b[32m'lora_dropout'\u001b[0m: \u001b[1;36m0.05\u001b[0m,\n",
      "    \u001b[32m'bias'\u001b[0m: \u001b[32m'none'\u001b[0m,\n",
      "    \u001b[32m'use_rslora'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
      "    \u001b[32m'init_lora_weights'\u001b[0m: \u001b[32m'gaussian'\u001b[0m,\n",
      "    \u001b[32m'output_dir'\u001b[0m: \u001b[32m'./training/paligemma'\u001b[0m,\n",
      "    \u001b[32m'metrics'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "        \u001b[1m<\u001b[0m\u001b[1;95mmaestro.trainer.common.utils.metrics.MeanAveragePrecisionMetric\u001b[0m\u001b[39m object \u001b[0m\n",
      "\u001b[39mat \u001b[0m\u001b[1;36m0x7f3348202290\u001b[0m\u001b[1m>\u001b[0m\n",
      "    \u001b[1m]\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "preprocessor_config.json: 100%|████████████████| 699/699 [00:00<00:00, 2.29MB/s]\n",
      "tokenizer_config.json: 100%|████████████████| 40.0k/40.0k [00:00<00:00, 233kB/s]\n",
      "tokenizer.model: 100%|█████████████████████| 4.26M/4.26M [00:00<00:00, 5.84MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 17.5M/17.5M [00:01<00:00, 9.04MB/s]\n",
      "added_tokens.json: 100%|█████████████████████| 24.0/24.0 [00:00<00:00, 96.7kB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 607/607 [00:00<00:00, 2.40MB/s]\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "config.json: 100%|█████████████████████████| 1.03k/1.03k [00:00<00:00, 4.02MB/s]\n",
      "FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "model.safetensors.index.json: 100%|████████| 62.6k/62.6k [00:00<00:00, 84.4MB/s]\n",
      "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0%|             | 0.00/4.99G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0%|    | 10.5M/4.99G [00:00<06:43, 12.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0%|    | 21.0M/4.99G [00:01<07:56, 10.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 31.5M/4.99G [00:02<07:58, 10.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 41.9M/4.99G [00:04<08:19, 9.90MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 52.4M/4.99G [00:05<08:29, 9.68MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 62.9M/4.99G [00:05<06:40, 12.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 73.4M/4.99G [00:06<07:19, 11.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|    | 83.9M/4.99G [00:07<07:36, 10.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|    | 94.4M/4.99G [00:09<08:22, 9.73MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|     | 105M/4.99G [00:09<07:46, 10.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|     | 115M/4.99G [00:11<09:01, 8.99MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 126M/4.99G [00:12<08:15, 9.80MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 136M/4.99G [00:13<08:22, 9.64MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 147M/4.99G [00:13<06:44, 12.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 157M/4.99G [00:15<08:34, 9.39MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 168M/4.99G [00:16<08:38, 9.29MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 178M/4.99G [00:17<06:58, 11.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 189M/4.99G [00:18<07:24, 10.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 199M/4.99G [00:19<08:57, 8.90MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 210M/4.99G [00:21<08:54, 8.94MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 220M/4.99G [00:21<07:48, 10.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 231M/4.99G [00:22<07:48, 10.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 241M/4.99G [00:23<07:59, 9.89MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 252M/4.99G [00:24<08:01, 9.83MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 262M/4.99G [00:26<08:33, 9.21MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 273M/4.99G [00:27<08:29, 9.24MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 283M/4.99G [00:28<08:26, 9.28MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 294M/4.99G [00:29<07:48, 10.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 304M/4.99G [00:30<07:16, 10.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 315M/4.99G [00:31<07:34, 10.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 325M/4.99G [00:32<08:52, 8.76MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 336M/4.99G [00:33<08:02, 9.63MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 346M/4.99G [00:34<08:06, 9.54MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 357M/4.99G [00:35<08:05, 9.54MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 367M/4.99G [00:37<08:08, 9.45MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 377M/4.99G [00:37<06:44, 11.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 388M/4.99G [00:38<07:35, 10.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 398M/4.99G [00:40<09:10, 8.33MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 409M/4.99G [00:41<07:19, 10.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 419M/4.99G [00:42<07:32, 10.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 430M/4.99G [00:43<08:25, 9.01MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 440M/4.99G [00:44<08:10, 9.27MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 451M/4.99G [00:45<07:25, 10.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 461M/4.99G [00:47<08:30, 8.86MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 472M/4.99G [00:47<07:39, 9.83MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▍    | 482M/4.99G [00:48<07:39, 9.80MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▍    | 493M/4.99G [00:49<07:03, 10.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▌    | 503M/4.99G [00:50<07:10, 10.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▌    | 514M/4.99G [00:51<07:19, 10.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 524M/4.99G [00:52<07:23, 10.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 535M/4.99G [00:54<07:42, 9.62MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 545M/4.99G [00:55<07:38, 9.67MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 556M/4.99G [00:56<08:55, 8.27MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 566M/4.99G [00:57<06:32, 11.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 577M/4.99G [00:58<06:45, 10.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 587M/4.99G [00:59<07:54, 9.28MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 598M/4.99G [01:00<07:45, 9.43MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 608M/4.99G [01:01<06:22, 11.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 619M/4.99G [01:02<06:39, 10.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 629M/4.99G [01:03<06:50, 10.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 640M/4.99G [01:04<07:17, 9.94MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 650M/4.99G [01:04<06:05, 11.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 661M/4.99G [01:06<07:20, 9.81MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 671M/4.99G [01:07<06:36, 10.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 682M/4.99G [01:07<06:14, 11.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 692M/4.99G [01:09<06:36, 10.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 703M/4.99G [01:10<06:45, 10.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 713M/4.99G [01:11<07:50, 9.07MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|▋    | 724M/4.99G [01:12<06:24, 11.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|▋    | 734M/4.99G [01:13<06:37, 10.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|▋    | 744M/4.99G [01:14<06:46, 10.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|▊    | 755M/4.99G [01:14<06:08, 11.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|▊    | 765M/4.99G [01:15<06:20, 11.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 776M/4.99G [01:17<06:34, 10.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 786M/4.99G [01:18<08:02, 8.70MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 797M/4.99G [01:19<06:20, 11.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 807M/4.99G [01:20<07:23, 9.41MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 818M/4.99G [01:21<07:18, 9.51MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 828M/4.99G [01:22<05:51, 11.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 839M/4.99G [01:23<06:08, 11.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 849M/4.99G [01:24<06:21, 10.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 860M/4.99G [01:26<08:18, 8.27MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 870M/4.99G [01:26<06:36, 10.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 881M/4.99G [01:27<06:54, 9.91MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 891M/4.99G [01:28<07:04, 9.65MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 902M/4.99G [01:29<06:32, 10.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 912M/4.99G [01:30<06:46, 10.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 923M/4.99G [01:31<06:55, 9.77MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 933M/4.99G [01:33<06:59, 9.66MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 944M/4.99G [01:33<06:31, 10.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 954M/4.99G [01:35<06:47, 9.90MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 965M/4.99G [01:36<07:25, 9.03MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▉    | 975M/4.99G [01:36<05:54, 11.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▉    | 986M/4.99G [01:38<06:56, 9.61MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▉    | 996M/4.99G [01:39<06:49, 9.74MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▊   | 1.01G/4.99G [01:40<06:47, 9.76MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▊   | 1.02G/4.99G [01:40<05:28, 12.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.03G/4.99G [01:41<05:47, 11.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.04G/4.99G [01:42<06:02, 10.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.05G/4.99G [01:43<06:05, 10.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.06G/4.99G [01:44<06:11, 10.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.07G/4.99G [01:46<07:02, 9.27MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▊   | 1.08G/4.99G [01:47<06:52, 9.48MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.09G/4.99G [01:48<06:41, 9.69MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.10G/4.99G [01:50<07:28, 8.65MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.11G/4.99G [01:50<05:27, 11.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.12G/4.99G [01:51<05:45, 11.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.13G/4.99G [01:52<06:49, 9.41MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.14G/4.99G [01:53<06:40, 9.60MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.15G/4.99G [01:54<05:19, 12.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.16G/4.99G [01:55<05:38, 11.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.17G/4.99G [01:57<07:22, 8.61MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.18G/4.99G [01:57<06:36, 9.59MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.20G/4.99G [01:59<06:39, 9.49MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.21G/4.99G [02:00<06:41, 9.42MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.22G/4.99G [02:01<06:42, 9.37MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|▉   | 1.23G/4.99G [02:01<05:25, 11.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|▉   | 1.24G/4.99G [02:02<05:44, 10.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|█   | 1.25G/4.99G [02:03<05:58, 10.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|█   | 1.26G/4.99G [02:04<05:36, 11.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|█   | 1.27G/4.99G [02:05<05:56, 10.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|█   | 1.28G/4.99G [02:06<06:08, 10.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|█   | 1.29G/4.99G [02:07<05:59, 10.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|█   | 1.30G/4.99G [02:08<05:34, 11.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|█   | 1.31G/4.99G [02:09<05:50, 10.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.32G/4.99G [02:10<05:54, 10.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.33G/4.99G [02:11<05:29, 11.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.34G/4.99G [02:12<05:43, 10.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.35G/4.99G [02:13<05:53, 10.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.36G/4.99G [02:14<05:55, 10.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|█   | 1.37G/4.99G [02:15<05:28, 11.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|█   | 1.38G/4.99G [02:16<05:39, 10.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|█   | 1.39G/4.99G [02:18<06:18, 9.48MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|█▏  | 1.41G/4.99G [02:18<04:37, 12.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|█▏  | 1.42G/4.99G [02:19<05:45, 10.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.43G/4.99G [02:20<05:53, 10.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.44G/4.99G [02:21<05:53, 10.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.45G/4.99G [02:22<05:27, 10.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.46G/4.99G [02:23<05:35, 10.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.47G/4.99G [02:24<05:21, 11.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.48G/4.99G [02:26<06:14, 9.37MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.49G/4.99G [02:26<04:34, 12.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.50G/4.99G [02:27<05:43, 10.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.51G/4.99G [02:28<05:25, 10.7MB/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "!maestro paligemma train --dataset={dataset.location} --epochs=10 --batch_size=6 --lr=5e-6 --metrics mean_average_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-cECkMgRt3R"
   },
   "source": [
    "## Evaluate Florence-2 on object detection task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_3QQrw6PCip",
    "outputId": "fbcf15cb-3d4a-4bed-f5c2-c03962f455f7"
   },
   "outputs": [],
   "source": [
    "!ls -la training/florence-2/1/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "qC_blu2c0x6z",
    "outputId": "13a1dc02-c1ad-4013-fd48-cf7cd6f9541e"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "Image(filename='training/florence-2/1/metrics/loss_plot.png', height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "GnZlFHrh1gzm",
    "outputId": "9ed19379-1f7e-481b-a03c-11f613e4f31e"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "Image(filename='training/florence-2/1/metrics/map50:95_plot.png', height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oc3Kuk_Yt5Ut"
   },
   "outputs": [],
   "source": [
    "!maestro florence2 evaluate \\\n",
    "--dataset={dataset.location} \\\n",
    "--model_id=/content/training/florence-2/1/checkpoints/best \\\n",
    "--metrics mean_average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoJIQVDv2BkN",
    "outputId": "d3ca3e2f-41cd-4587-d8d5-fa1244d39b1f"
   },
   "outputs": [],
   "source": [
    "!cat /content/evaluation/florence-2/metrics/evaluation.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZEJG3haPMDN",
    "outputId": "5462a558-79f3-4b02-b7ae-47779b8759df"
   },
   "outputs": [],
   "source": [
    "!ls -la training/florence-2/1/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9IOnjDER2JW"
   },
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKwCDU1cQVXq"
   },
   "outputs": [],
   "source": [
    "from maestro.trainer.models.florence_2.checkpoints import load_model\n",
    "\n",
    "processor, model = load_model(model_id_or_path=\"/content/training/florence-2/1/checkpoints/best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "BLe4jyaWPPse",
    "outputId": "d58d7233-7808-472d-920a-2be06bfbc7c1"
   },
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from maestro.trainer.common.data_loaders.datasets import JSONLDataset\n",
    "\n",
    "ds = JSONLDataset(\n",
    "    jsonl_file_path = f\"{dataset.location}/valid/annotations.jsonl\",\n",
    "    image_directory_path = f\"{dataset.location}/valid/\"\n",
    ")\n",
    "\n",
    "image, _ = ds[0]\n",
    "text = \"<OD>\"\n",
    "task = \"<OD>\"\n",
    "\n",
    "inputs = processor(text=text, images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "generated_ids = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    pixel_values=inputs[\"pixel_values\"],\n",
    "    max_new_tokens=1024,\n",
    "    num_beams=3\n",
    ")\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "response = processor.post_process_generation(generated_text, task=task, image_size=image.size)\n",
    "detections = sv.Detections.from_lmm(sv.LMM.FLORENCE_2, response, resolution_wh=image.size)\n",
    "\n",
    "box_annotator = sv.BoxAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "label_annotator = sv.LabelAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "\n",
    "image = box_annotator.annotate(image, detections)\n",
    "image = label_annotator.annotate(image, detections)\n",
    "image.thumbnail((600, 600))\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
